{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fnmatch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "PROD_CONCAT = \"ProdConcat\"\n",
    "PRECIO_VENTA = \"Precio Venta\"\n",
    "CANTIDAD = \"Cantidad\"\n",
    "FECHA = \"Fecha\"\n",
    "ALMACEN = \"Almacen\"\n",
    "IVA = .16\n",
    "CIEN = 100\n",
    "MES = \"Mes\"\n",
    "PREDICCION = \"Prediccion Diciembre\"\n",
    "\n",
    "CLASIFICACION = \"CLASIFICACION\"\n",
    "N1 = \"N1\"\n",
    "N2 = \"N2\"\n",
    "N3 = \"N3\"\n",
    "\n",
    "def unir_dataframes(lista_df):\n",
    "    \"\"\"\n",
    "    Une una lista de DataFrames en uno solo, validando que todos tengan las mismas columnas.\n",
    "\n",
    "    :param lista_df: Lista de DataFrames a unir.\n",
    "    :return: DataFrame combinado si todos los DataFrames tienen las mismas columnas.\n",
    "    :raises ValueError: Si los DataFrames no tienen las mismas columnas.\n",
    "    \"\"\"\n",
    "    # Validar que la lista no esté vacía\n",
    "    if not lista_df:\n",
    "        raise ValueError(\"La lista de DataFrames está vacía.\")\n",
    "    \n",
    "    # Obtener las columnas del primer DataFrame como referencia\n",
    "    columnas_referencia = lista_df[0].columns\n",
    "    \n",
    "    # Verificar que todos los DataFrames tengan las mismas columnas\n",
    "    for i, df in enumerate(lista_df):\n",
    "        if not df.columns.equals(columnas_referencia):\n",
    "            raise ValueError(f\"El DataFrame en la posición {i} no tiene las mismas columnas.\")\n",
    "    \n",
    "    # Concatenar los DataFrames si pasan la validación\n",
    "    df_resultado = pd.concat(lista_df, ignore_index=True)\n",
    "    return df_resultado\n",
    "\n",
    "def generar_excel_by_dataframe(df, nombre_base):\n",
    "    \"\"\"\n",
    "    Genera un archivo Excel a partir de un DataFrame, añadiendo la fecha y hora actual al nombre del archivo.\n",
    "    :param df: DataFrame a exportar.\n",
    "    :param nombre_base: Nombre base del archivo (sin extensión).\n",
    "    :return: Ruta completa del archivo generado.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Obtener la fecha y hora actuales en formato 'YYYYMMDD_HHMMSS'\n",
    "        fecha_hora = datetime.now().strftime(\"%Y-%m-%dT%H-%M-%S\")\n",
    "        \n",
    "        # Construir el nombre del archivo\n",
    "        nombre_archivo = f\"{nombre_base}_{fecha_hora}.xlsx\"\n",
    "        \n",
    "        # Exportar el DataFrame a Excel\n",
    "        df.to_excel(nombre_archivo, index=False, engine=\"openpyxl\")\n",
    "        \n",
    "        print(f\"Archivo Excel generado exitosamente: {nombre_archivo}\")\n",
    "        return nombre_archivo\n",
    "    except Exception as e:\n",
    "        print(f\"Error al generar el archivo Excel: {e}\")\n",
    "        return None\n",
    "\n",
    "def archivos_excel_by_coincidencia(directorio: str, cadena: str):\n",
    "    archivos_excel = []\n",
    "    patron = f\"*{cadena}*.xlsx\"\n",
    "    \n",
    "    for archivo in os.listdir(directorio):\n",
    "        if fnmatch.fnmatch(archivo, patron):\n",
    "            archivos_excel.append(archivo)\n",
    "\n",
    "    return archivos_excel\n",
    "    \n",
    "def filtrar_columnas_dataframe(dataframe, columnas):\n",
    "    \"\"\"\n",
    "    Devuelve un DataFrame que contiene solo las columnas especificadas.\n",
    "\n",
    "    :param dataframe: DataFrame de pandas del que se desea conservar las columnas.\n",
    "    :param columnas: Lista de nombres de columnas a conservar.\n",
    "    :return: DataFrame con solo las columnas especificadas.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Verificar cuáles columnas existen en el DataFrame\n",
    "        columnas_existentes = [col for col in columnas if col in dataframe.columns]\n",
    "        columnas_no_existentes = [col for col in columnas if col not in dataframe.columns]\n",
    "\n",
    "        if columnas_no_existentes:\n",
    "            print(f\"Las siguientes columnas no existen en el DataFrame: {columnas_no_existentes}\")\n",
    "\n",
    "        # Columnas filtradas\n",
    "        dataframe = dataframe[columnas_existentes]\n",
    "    except Exception as e:\n",
    "        print(f\"Se produjo un error al intentar filtrar las columnas: {e}\")\n",
    "\n",
    "    return dataframe\n",
    "    \n",
    "def validar_datos_numericos_dataframe(dataframe, columnas):\n",
    "    \"\"\"\n",
    "    Reemplaza ceros en las columnas especificadas de un DataFrame con NaN.\n",
    "    :param dataframe: DataFrame en el que se procesarán las columnas.\n",
    "    :param columnas: Lista de nombres de columnas donde se reemplazarán los ceros por NaN.\n",
    "    :return: DataFrame con los ceros reemplazados por NaN en las columnas especificadas.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Validar que las columnas existan en el DataFrame\n",
    "        columnas_validas = [col for col in columnas if col in dataframe.columns]\n",
    "        # Reemplazar ceros por NaN en las columnas válidas\n",
    "        dataframe[columnas_validas] = dataframe[columnas_validas].replace(0, np.nan)\n",
    "        print(f\"Ceros reemplazados por NaN en las columnas: {columnas_validas}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error al reemplazar ceros por NaN: {e}\")\n",
    "    return dataframe\n",
    "    \n",
    "def crear_carpeta(base_nombre_carpeta, ruta_base=\".\"):\n",
    "    \"\"\"\n",
    "    Crea una carpeta con un nombre que incluye la fecha y hora actual al final.\n",
    "    \n",
    "    :param base_nombre_carpeta: Nombre base para la carpeta.\n",
    "    :param ruta_base: Ruta donde se creará la carpeta. Por defecto, en el directorio actual.\n",
    "    :return: Ruta completa de la carpeta creada.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Obtener la fecha y hora actuales en formato 'YYYY-MM-DDTHH-MM-SS'\n",
    "        fecha_hora = datetime.now().strftime(\"%Y-%m-%dT%H-%M-%S\")\n",
    "        \n",
    "        # Construir el nombre completo de la carpeta\n",
    "        nombre_completo_carpeta = f\"{base_nombre_carpeta}_{fecha_hora}\"\n",
    "        ruta_completa_carpeta = os.path.join(ruta_base, nombre_completo_carpeta)\n",
    "        \n",
    "        # Crear la carpeta\n",
    "        os.makedirs(ruta_completa_carpeta, exist_ok=True)\n",
    "        print(f\"Carpeta creada: {ruta_completa_carpeta}\")\n",
    "        return ruta_completa_carpeta\n",
    "    except Exception as e:\n",
    "        print(f\"Error al crear la carpeta: {e}\")\n",
    "        return None\n",
    "\n",
    "def mover_archivos_a_carpeta(lista_archivos, carpeta_destino):\n",
    "    \"\"\"\n",
    "    Mueve una lista de archivos a una carpeta destino.\n",
    "    :param lista_archivos: Lista con las rutas de los archivos a mover.\n",
    "    :param carpeta_destino: Ruta de la carpeta destino.\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Crear la carpeta destino si no existe\n",
    "        carpeta_destino = crear_carpeta(carpeta_destino)\n",
    "        for archivo in lista_archivos:\n",
    "            if os.path.isfile(archivo):  # Verificar que el archivo existe\n",
    "                destino = os.path.join(carpeta_destino, os.path.basename(archivo))  # Ruta destino\n",
    "                shutil.move(archivo, destino)  # Mover el archivo\n",
    "                print(f\"Archivo movido: {archivo} -> {destino}\")\n",
    "            else:\n",
    "                print(f\"El archivo no existe: {archivo}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error al mover archivos: {e}\")\n",
    "\n",
    "def validar_archivos(lista_archivos):\n",
    "    \"\"\"\n",
    "    Valida que una lista de archivos no contenga valores vacíos.\n",
    "    :param lista_archivos: Lista de rutas de archivos.\n",
    "    :return: True si todos los archivos son válidos, False si hay archivos faltantes.\n",
    "    \"\"\"\n",
    "    # Filtrar archivos vacíos\n",
    "    archivos_faltantes = [archivo for archivo in lista_archivos if archivo == \"\"]\n",
    "    \n",
    "    if archivos_faltantes:\n",
    "        print(\"Error: Faltan archivos necesarios para el proceso del reporte.\")\n",
    "       \n",
    "    \n",
    "    print(\"Todos los archivos son válidos.\")\n",
    "    return True\n",
    "\n",
    "def validar_listas_archivos_no_vacias(lista_de_listas):\n",
    "    \"\"\"\n",
    "    Valida que ninguna lista dentro de una lista de listas esté vacía.\n",
    "    \n",
    "    :param lista_de_listas: Lista de listas de strings.\n",
    "    :return: True si ninguna lista está vacía.\n",
    "    :raises ValueError: Si alguna lista está vacía.\n",
    "    \"\"\"\n",
    "    for i, lista in enumerate(lista_de_listas):\n",
    "        if not lista:  # Verifica si la lista está vacía\n",
    "            print(\"Error: Faltan archivos necesarios para el proceso del reporte.\")\n",
    "            sys.exit(1)  # Rompe la ejecución con un código de error\n",
    "            return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "def crear_dataframe_from_excel(archivo: str, columnas: list = None, hoja: str = None):\n",
    "    \"\"\"\n",
    "    Lee un archivo de Excel y crea un DataFrame filtrado con las columnas especificadas.\n",
    "\n",
    "    :param archivo: Ruta del archivo Excel a leer.\n",
    "    :param columnas: Lista de nombres de columnas que se desean extraer del archivo.\n",
    "    :param hoja: Nombre de la hoja a leer. Si no se especifica, se lee la primera hoja por defecto.\n",
    "    :return: DataFrame con las columnas filtradas, o None si ocurre un error.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Inicializar el DataFrame\n",
    "        df = None\n",
    "        # Leer el archivo de Excel\n",
    "        # Si no se especifica una hoja, se lee la primera por defecto\n",
    "        if hoja is None:\n",
    "            df = pd.read_excel(archivo, engine='openpyxl')\n",
    "        else:\n",
    "            # Si se especifica una hoja, se intenta leer esa hoja en particular\n",
    "            df = pd.read_excel(archivo, engine='openpyxl', sheet_name=hoja)\n",
    "        # Filtrar las columnas especificadas por el usuario\n",
    "        if columnas:\n",
    "            df = df[columnas]\n",
    "        # Devolver el DataFrame filtrado\n",
    "        return df\n",
    "    # Manejo de excepciones\n",
    "    except FileNotFoundError:\n",
    "        # Error si el archivo no se encuentra en la ruta especificada\n",
    "        print(f\"El archivo {archivo} no fue encontrado.\")\n",
    "    except KeyError as e:\n",
    "        # Error si una o más columnas no existen en el archivo\n",
    "        print(f\"Una o más columnas no se encuentran en el archivo: {e}\")\n",
    "    except ValueError:\n",
    "        # Error si la hoja especificada no existe en el archivo\n",
    "        print(f\"La hoja '{hoja}' no existe en el archivo {archivo}.\")\n",
    "    except Exception as e:\n",
    "        # Captura cualquier otro error no previsto\n",
    "        print(f\"Se produjo un error al procesar el archivo: {e}\")\n",
    "\n",
    "def crear_dataframe_unido_por_coincidencia_excel(directorio: str = \"./\", cadena: str = \"\", columnas: list = None, hoja: str = None):\n",
    "    \"\"\"\n",
    "    Busca archivos Excel en un directorio que coincidan con una cadena en su nombre, \n",
    "    los convierte en DataFrames (opcionalmente filtrando columnas y seleccionando una hoja específica)\n",
    "    y los une en un solo DataFrame.\n",
    "\n",
    "    :param directorio: Ruta del directorio donde buscar archivos Excel (por defecto \"./\").\n",
    "    :param cadena: Cadena de coincidencia para buscar archivos.\n",
    "    :param columnas: Lista de columnas a seleccionar de cada archivo (opcional). Si no se proporciona, se cargan todas.\n",
    "    :param hoja: Nombre de la hoja a leer (opcional). Si no se proporciona, se lee la primera hoja.\n",
    "    :return: DataFrame unido de todos los archivos encontrados y leídos correctamente.\n",
    "    :raises FileNotFoundError: Si no se encuentra ningún archivo que coincida con la búsqueda.\n",
    "    :raises ValueError: Si no se pudieron leer archivos o unir DataFrames correctamente.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Buscar archivos Excel en el directorio que contengan la cadena en su nombre\n",
    "    archivos_coincidentes = archivos_excel_by_coincidencia(directorio, cadena)\n",
    "    \n",
    "    # Si no se encuentran archivos, lanzar un error\n",
    "    if not archivos_coincidentes:\n",
    "        raise FileNotFoundError(f\"No se encontraron archivos que coincidan con '{cadena}' en {directorio}.\")\n",
    "\n",
    "    # Lista para almacenar los DataFrames generados a partir de los archivos encontrados\n",
    "    lista_df = []\n",
    "\n",
    "    # Iterar sobre cada archivo encontrado\n",
    "    for archivo in archivos_coincidentes:\n",
    "        ruta_completa = os.path.join(directorio, archivo)  # Crear la ruta completa del archivo\n",
    "        \n",
    "        try:\n",
    "            # Crear un DataFrame a partir del archivo Excel, con la opción de filtrar columnas y seleccionar hoja\n",
    "            df = crear_dataframe_from_excel(archivo=ruta_completa, columnas=columnas, hoja=hoja)\n",
    "            lista_df.append(df)  # Añadir el DataFrame a la lista\n",
    "        \n",
    "        except Exception as e:\n",
    "            # Capturar errores durante la lectura de los archivos\n",
    "            print(f\"Error al leer el archivo {archivo}: {e}\")\n",
    "    \n",
    "    # Si hay DataFrames válidos en la lista, unirlos\n",
    "    if lista_df:\n",
    "        return unir_dataframes(lista_df)\n",
    "    \n",
    "    # Si no se pudieron leer los archivos correctamente, lanzar un error\n",
    "    else:\n",
    "        raise ValueError(\"No se pudieron leer los archivos correctamente.\")\n",
    "\n",
    "def ordenar_columnas_al_lado(df, columna_referencia, columnas_a_mover):\n",
    "    \"\"\"\n",
    "    Ordena una lista de columnas al lado de una columna de referencia en un DataFrame.\n",
    "\n",
    "    :param df: DataFrame a modificar.\n",
    "    :param columna_referencia: Columna donde se insertarán las demás columnas al lado.\n",
    "    :param columnas_a_mover: Lista de columnas que se deben mover al lado de la columna de referencia.\n",
    "    :return: DataFrame con las columnas reordenadas.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Validar que las columnas estén en el DataFrame\n",
    "        columnas_faltantes = [col for col in columnas_a_mover + [columna_referencia] if col not in df.columns]\n",
    "        if columnas_faltantes:\n",
    "            raise ValueError(f\"Las siguientes columnas no están en el DataFrame: {columnas_faltantes}\")\n",
    "\n",
    "        # Obtener la lista de columnas actuales\n",
    "        columnas_actuales = df.columns.tolist()\n",
    "\n",
    "        # Determinar la posición de la columna de referencia\n",
    "        indice_referencia = columnas_actuales.index(columna_referencia)\n",
    "\n",
    "        # Crear una nueva lista de columnas manteniendo el orden original\n",
    "        nuevas_columnas = []\n",
    "        for col in columnas_actuales:\n",
    "            if col == columna_referencia:\n",
    "                # Insertar la columna de referencia\n",
    "                nuevas_columnas.append(col)\n",
    "                # Insertar las columnas a mover justo después de la columna de referencia\n",
    "                nuevas_columnas.extend([c for c in columnas_a_mover if c in columnas_actuales])\n",
    "            elif col not in columnas_a_mover:\n",
    "                # Mantener otras columnas que no se están moviendo\n",
    "                nuevas_columnas.append(col)\n",
    "\n",
    "        # Reordenar el DataFrame con las nuevas columnas\n",
    "        df = df[nuevas_columnas]\n",
    "\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error al reordenar las columnas: {e}\")\n",
    "        return df  # Devolver el DataFrame original en caso de error\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtener_dataframe_ventas():\n",
    "    columnas_ventas_acc_tel = [ALMACEN, PROD_CONCAT, CANTIDAD, \"PrecioVenta\", FECHA]\n",
    "    df_ventas_acc_tel = crear_dataframe_unido_por_coincidencia_excel(directorio=\"./Ventas\", cadena=\"Analisis de Ventas\", columnas=columnas_ventas_acc_tel)\n",
    "    df_ventas_acc_tel = validar_datos_numericos_dataframe(df_ventas_acc_tel, [CANTIDAD,\"PrecioVenta\"])\n",
    "    # Definir el mapeo de columnas para renombrar\n",
    "    mapeo_columnas_acc_tel = {\n",
    "        \"PrecioVenta\": PRECIO_VENTA\n",
    "    }\n",
    "    # Renombrar las columnas del DataFrame usando el mapeo\n",
    "    df_ventas_acc_tel.rename(columns=mapeo_columnas_acc_tel, inplace=True)\n",
    "    df_ventas_acc_tel = validar_datos_numericos_dataframe(df_ventas_acc_tel, [CANTIDAD, PRECIO_VENTA])\n",
    "\n",
    "    columnas_ventas_refacc = [\"Almacén Salida Reparación\", \"Producto\", CANTIDAD, \"PrecioVentaSinIva\", \"Fecha Salida Reparación\"]\n",
    "    df_ventas_refacc = crear_dataframe_unido_por_coincidencia_excel(directorio=\"./Ventas\", cadena=\"Refacciones_Consumidas\", columnas=columnas_ventas_refacc)\n",
    "    # Definir el mapeo de columnas para renombrar\n",
    "    mapeo_columnas_refacc = {\n",
    "        \"Almacén Salida Reparación\": ALMACEN,\n",
    "        \"Producto\": PROD_CONCAT,\n",
    "        \"PrecioVentaSinIva\": PRECIO_VENTA,\n",
    "        \"Fecha Salida Reparación\": FECHA\n",
    "    }\n",
    "    # Renombrar las columnas del DataFrame usando el mapeo\n",
    "    df_ventas_refacc.rename(columns=mapeo_columnas_refacc, inplace=True)\n",
    "    df_ventas_refacc = validar_datos_numericos_dataframe(df_ventas_refacc, [CANTIDAD, PRECIO_VENTA])\n",
    "    # Calcular el 16% y sumarlo a la columna Costo_Compra\n",
    "    df_ventas_refacc[PRECIO_VENTA] = df_ventas_refacc[PRECIO_VENTA]+(df_ventas_refacc[PRECIO_VENTA]*IVA)\n",
    "    #Fusionamos las ventas de accesorios, telefonía y refacciones\n",
    "    df_ventas_unificadas = unir_dataframes([df_ventas_acc_tel, df_ventas_refacc])\n",
    "    # Asegurarse de que la columna Fecha está en el formato correcto\n",
    "    df_ventas_unificadas[FECHA] = pd.to_datetime(df_ventas_unificadas[FECHA], format='%b %d %Y %I:%M%p')\n",
    "    # Extraer el número del mes de la columna 'Fecha'\n",
    "    df_ventas_unificadas[MES] = df_ventas_unificadas[FECHA].dt.month\n",
    "    df_ventas_unificadas.drop(columns=[FECHA], inplace=True)\n",
    "    return df_ventas_unificadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtrar_ventas_por_mes(df_ventas, lista_meses):\n",
    "    \"\"\"\n",
    "    Filtra el DataFrame de ventas por los meses especificados en la lista.\n",
    "\n",
    "    :param df_ventas: DataFrame que contiene una columna 'Mes' en formato numerico del 1 al 12\n",
    "    :param lista_meses: Lista de números que representan los meses a filtrar (1 para enero, 2 para febrero, etc.).\n",
    "    :return: DataFrame filtrado con las ventas de los meses indicados.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Filtrar el DataFrame según los meses especificados\n",
    "        df_filtrado = df_ventas[df_ventas['Mes'].isin(lista_meses)]\n",
    "        return df_filtrado\n",
    "    except Exception as e:\n",
    "        print(f\"Error al filtrar por mes: {e}\")\n",
    "        return pd.DataFrame()  # Retorna un DataFrame vacío en caso de error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agrupa_ventas_by_prodconcat(df_ventas):\n",
    "    df_ventas = filtrar_columnas_dataframe(df_ventas, [PROD_CONCAT, ALMACEN, CANTIDAD, MES])\n",
    "    df_ventas = df_ventas.groupby([PROD_CONCAT, ALMACEN, MES]).agg({\n",
    "        CANTIDAD: 'sum'\n",
    "    }).reset_index()\n",
    "    return df_ventas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "def predecir_ventas_diciembre_rl(df_ventas):\n",
    "    # Validar que el DataFrame tenga las columnas necesarias\n",
    "    columnas_requeridas = [ALMACEN, PROD_CONCAT, CANTIDAD, MES]\n",
    "    for columna in columnas_requeridas:\n",
    "        if columna not in df_ventas.columns:\n",
    "            raise ValueError(f\"Falta la columna {columna} en el DataFrame.\")\n",
    "\n",
    "    # Crear una copia del DataFrame para evitar modificar el original\n",
    "    df = df_ventas.copy()\n",
    "\n",
    "    # Codificar 'Almacen' y 'ProdConcat' como números (Label Encoding)\n",
    "    df[ALMACEN] = df[ALMACEN].astype('category').cat.codes\n",
    "    df[PROD_CONCAT] = df[PROD_CONCAT].astype('category').cat.codes\n",
    "\n",
    "    # Definir características (X) y la variable objetivo (y)\n",
    "    X = df[[ALMACEN, PROD_CONCAT, MES]]\n",
    "    y = df[CANTIDAD]\n",
    "\n",
    "    # Dividir datos en entrenamiento y prueba (80% - 20%)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "    # Crear y entrenar el modelo de regresión lineal\n",
    "    modelo = LinearRegression()\n",
    "    modelo.fit(X_train, y_train)\n",
    "\n",
    "    # Hacer predicciones sobre el conjunto de prueba\n",
    "    y_pred = modelo.predict(X_test)\n",
    "\n",
    "    # Calcular el error medio absoluto\n",
    "    error = mean_absolute_error(y_test, y_pred)\n",
    "    print(f\"Error Medio Absoluto (MAE): {error:.2f} unidades.\")\n",
    "\n",
    "    # Predecir ventas para diciembre (Mes = 12)\n",
    "    diciembre = X.copy()\n",
    "    diciembre[MES] = 12\n",
    "\n",
    "    # Hacer predicción para diciembre\n",
    "    diciembre['Prediccion Diciembre'] = modelo.predict(diciembre)\n",
    "\n",
    "    # Descodificar 'Almacen' y 'ProdConcat' para devolver los valores originales\n",
    "    diciembre[ALMACEN] = pd.Categorical.from_codes(diciembre[ALMACEN], df_ventas[ALMACEN].astype('category').cat.categories)\n",
    "    diciembre[PROD_CONCAT] = pd.Categorical.from_codes(diciembre[PROD_CONCAT], df_ventas[PROD_CONCAT].astype('category').cat.categories)\n",
    "\n",
    "    # Filtrar y mostrar predicción final para diciembre\n",
    "    resultado_final = diciembre[[ALMACEN, PROD_CONCAT, 'Prediccion Diciembre']].drop_duplicates()\n",
    "\n",
    "    return resultado_final\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import pandas as pd\n",
    "\n",
    "def predecir_ventas_diciembre_rf(df_ventas):\n",
    "    \"\"\"\n",
    "    Predice las ventas de diciembre utilizando Random Forest.\n",
    "\n",
    "    :param df_ventas: DataFrame con columnas ['Almacen', 'ProdConcat', 'Cantidad', 'Mes'].\n",
    "    :return: DataFrame con predicciones de ventas para diciembre.\n",
    "    \"\"\"\n",
    "    # Validar que el DataFrame tenga las columnas necesarias\n",
    "    columnas_requeridas = [ALMACEN, PROD_CONCAT, CANTIDAD, MES]\n",
    "    for columna in columnas_requeridas:\n",
    "        if columna not in df_ventas.columns:\n",
    "            raise ValueError(f\"Falta la columna {columna} en el DataFrame.\")\n",
    "\n",
    "    # Crear una copia para no modificar el original\n",
    "    df = df_ventas.copy()\n",
    "\n",
    "    # Codificar 'Almacen' y 'ProdConcat' como números (Label Encoding)\n",
    "    df[ALMACEN] = df[ALMACEN].astype('category').cat.codes\n",
    "    df[PROD_CONCAT] = df[PROD_CONCAT].astype('category').cat.codes\n",
    "\n",
    "    # Definir características (X) y la variable objetivo (y)\n",
    "    X = df[[ALMACEN, PROD_CONCAT, MES]]\n",
    "    y = df[CANTIDAD]\n",
    "\n",
    "    # Dividir los datos en entrenamiento (90%) y prueba (10%)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "    # Crear y entrenar el modelo Random Forest\n",
    "    modelo_rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    modelo_rf.fit(X_train, y_train)\n",
    "\n",
    "    # Hacer predicciones sobre el conjunto de prueba\n",
    "    y_pred = modelo_rf.predict(X_test)\n",
    "\n",
    "    # Calcular el error medio absoluto\n",
    "    error_rf = mean_absolute_error(y_test, y_pred)\n",
    "    print(f\"Error Medio Absoluto (MAE) con Random Forest: {error_rf:.2f} unidades.\")\n",
    "\n",
    "    # Predecir ventas para diciembre (Mes = 12)\n",
    "    diciembre = X.copy()\n",
    "    diciembre[MES] = 12\n",
    "\n",
    "    # Hacer predicción para diciembre\n",
    "    diciembre[PREDICCION] = modelo_rf.predict(diciembre)\n",
    "\n",
    "    # Descodificar 'Almacen' y 'ProdConcat' para devolver los valores originales\n",
    "    diciembre[ALMACEN] = pd.Categorical.from_codes(diciembre[ALMACEN], df_ventas[ALMACEN].astype('category').cat.categories)\n",
    "    diciembre[PROD_CONCAT] = pd.Categorical.from_codes(diciembre[PROD_CONCAT], df_ventas[PROD_CONCAT].astype('category').cat.categories)\n",
    "\n",
    "    # Filtrar y mostrar predicción final para diciembre\n",
    "    resultado_final = diciembre[[ALMACEN, PROD_CONCAT, 'Prediccion Diciembre']].drop_duplicates()\n",
    "\n",
    "    return resultado_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediccion_regresion_lineal(df_ventas_enero_nov, df_ventas_dic):\n",
    "    # Llamar la función para predecir ventas de diciembre\n",
    "    prediccion_diciembre_rl = predecir_ventas_diciembre_rl(df_ventas_enero_nov)\n",
    "\n",
    "    df_sum_pred = prediccion_diciembre_rl.copy(deep=True)\n",
    "    df_sum_pred = filtrar_columnas_dataframe(df_sum_pred, [PROD_CONCAT, PREDICCION])\n",
    "    df_sum_pred = df_sum_pred.groupby([PROD_CONCAT]).agg({\n",
    "        PREDICCION: 'sum'\n",
    "    }).reset_index()\n",
    "\n",
    "    # Definir el mapeo de columnas para renombrar\n",
    "    mapeo_columnas_sum_pred = {\n",
    "        PREDICCION: \"Prediccion Global\"\n",
    "    }\n",
    "    # Renombrar las columnas del DataFrame usando el mapeo\n",
    "    df_sum_pred.rename(columns=mapeo_columnas_sum_pred, inplace=True)\n",
    "\n",
    "    # Realizar el pivote\n",
    "    df_pivot_rl = prediccion_diciembre_rl.pivot(\n",
    "        index=PROD_CONCAT,\n",
    "        columns=ALMACEN,\n",
    "        values=PREDICCION\n",
    "    ).reset_index()\n",
    "\n",
    "    df_pivot_rl = pd.merge(df_pivot_rl, df_sum_pred, on=[PROD_CONCAT], how=\"inner\")\n",
    "\n",
    "    df_sum_ventas = df_ventas_dic.copy(deep=True)\n",
    "    df_sum_ventas = filtrar_columnas_dataframe(df_sum_ventas, [PROD_CONCAT, CANTIDAD])\n",
    "    df_sum_ventas = df_sum_ventas.groupby([PROD_CONCAT]).agg({\n",
    "        CANTIDAD: 'sum'\n",
    "    }).reset_index()\n",
    "\n",
    "        # Definir el mapeo de columnas para renombrar\n",
    "    mapeo_columnas_sum_ventas = {\n",
    "        CANTIDAD: \"Ventas Globales\"\n",
    "    }\n",
    "    # Renombrar las columnas del DataFrame usando el mapeo\n",
    "    df_sum_ventas.rename(columns=mapeo_columnas_sum_ventas, inplace=True)\n",
    "\n",
    "    df_pivot_dic = df_ventas_dic.pivot(\n",
    "        index=PROD_CONCAT,\n",
    "        columns=ALMACEN,\n",
    "        values=CANTIDAD\n",
    "    ).reset_index()\n",
    "\n",
    "    df_pivot_dic = pd.merge(df_pivot_dic, df_sum_ventas, on=[PROD_CONCAT], how=\"inner\")\n",
    "\n",
    "    # Realizar el merge entre predicciones y ventas de diciembre (REGRESION LINEAL)\n",
    "    df_prediccion_v_real_dic_rl = pd.merge(df_pivot_rl, df_pivot_dic, \n",
    "                            on=[PROD_CONCAT], \n",
    "                            how=\"outer\",  # Mantiene todos los registros (outer), inner para intersección\n",
    "                            suffixes=('_pred', '_real'))  # Sufijos para diferenciar columnas\n",
    "    \n",
    "    return df_prediccion_v_real_dic_rl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prediccion_random_forest(df_ventas_enero_nov, df_ventas_dic):\n",
    "    # Llamar la función para predecir ventas de diciembre\n",
    "    prediccion_diciembre_rf = predecir_ventas_diciembre_rf(df_ventas_enero_nov)\n",
    "\n",
    "    \n",
    "    df_sum_pred = prediccion_diciembre_rf.copy(deep=True)\n",
    "    df_sum_pred = filtrar_columnas_dataframe(df_sum_pred, [PROD_CONCAT, PREDICCION])\n",
    "    df_sum_pred = df_sum_pred.groupby([PROD_CONCAT]).agg({\n",
    "        PREDICCION: 'sum'\n",
    "    }).reset_index()\n",
    "\n",
    "    # Definir el mapeo de columnas para renombrar\n",
    "    mapeo_columnas_sum_pred = {\n",
    "        PREDICCION: \"Prediccion Global\"\n",
    "    }\n",
    "    # Renombrar las columnas del DataFrame usando el mapeo\n",
    "    df_sum_pred.rename(columns=mapeo_columnas_sum_pred, inplace=True)\n",
    "\n",
    "    # Realizar el pivote\n",
    "    df_pivot_rf = prediccion_diciembre_rf.pivot(\n",
    "        index=PROD_CONCAT,\n",
    "        columns=ALMACEN,\n",
    "        values=PREDICCION\n",
    "    ).reset_index()\n",
    "\n",
    "    df_pivot_rf = pd.merge(df_pivot_rf, df_sum_pred, on=[PROD_CONCAT], how=\"inner\")\n",
    "    \n",
    "    df_sum_ventas = df_ventas_dic.copy(deep=True)\n",
    "    df_sum_ventas = filtrar_columnas_dataframe(df_sum_ventas, [PROD_CONCAT, CANTIDAD])\n",
    "    df_sum_ventas = df_sum_ventas.groupby([PROD_CONCAT]).agg({\n",
    "        CANTIDAD: 'sum'\n",
    "    }).reset_index()\n",
    "\n",
    "        # Definir el mapeo de columnas para renombrar\n",
    "    mapeo_columnas_sum_ventas = {\n",
    "        CANTIDAD: \"Ventas Globales\"\n",
    "    }\n",
    "    # Renombrar las columnas del DataFrame usando el mapeo\n",
    "    df_sum_ventas.rename(columns=mapeo_columnas_sum_ventas, inplace=True)\n",
    "\n",
    "    df_pivot_dic = df_ventas_dic.pivot(\n",
    "        index=PROD_CONCAT,\n",
    "        columns=ALMACEN,\n",
    "        values=CANTIDAD\n",
    "    ).reset_index()\n",
    "\n",
    "    df_pivot_dic = pd.merge(df_pivot_dic, df_sum_ventas, on=[PROD_CONCAT], how=\"inner\")\n",
    "\n",
    "    # Realizar el merge entre predicciones y ventas de diciembre (REGRESION LINEAL)\n",
    "    df_prediccion_v_real_dic_rf = pd.merge(df_pivot_rf, df_pivot_dic, \n",
    "                            on=[PROD_CONCAT], \n",
    "                            how=\"outer\",  # Mantiene todos los registros (outer), inner para intersección\n",
    "                            suffixes=('_pred', '_real'))  # Sufijos para diferenciar columnas\n",
    "    \n",
    "    return df_prediccion_v_real_dic_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ceros reemplazados por NaN en las columnas: ['Cantidad', 'PrecioVenta']\n",
      "Ceros reemplazados por NaN en las columnas: ['Cantidad', 'Precio Venta']\n",
      "Ceros reemplazados por NaN en las columnas: ['Cantidad', 'Precio Venta']\n",
      "Error Medio Absoluto (MAE): 5.13 unidades.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gibra\\AppData\\Local\\Temp\\ipykernel_33668\\1689136245.py:7: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df_sum_pred = df_sum_pred.groupby([PROD_CONCAT]).agg({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo Excel generado exitosamente: PREDICCION-DICIEMBRE-RL_2024-12-24T03-20-51.xlsx\n",
      "Error Medio Absoluto (MAE) con Random Forest: 1.53 unidades.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gibra\\AppData\\Local\\Temp\\ipykernel_33668\\3914037794.py:8: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df_sum_pred = df_sum_pred.groupby([PROD_CONCAT]).agg({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo Excel generado exitosamente: PREDICCION-DICIEMBRE-RF_2024-12-24T03-21-01.xlsx\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'PREDICCION-DICIEMBRE-RF_2024-12-24T03-21-01.xlsx'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ventas = obtener_dataframe_ventas()\n",
    "\n",
    "df_ventas_agrupadas_by_prodConcat = agrupa_ventas_by_prodconcat(df_ventas.copy(deep=True))\n",
    "\n",
    "df_ventas_enero_nov = filtrar_ventas_por_mes(df_ventas=df_ventas_agrupadas_by_prodConcat.copy(deep=True), lista_meses=[1,2,3,4,5,6,7,8,9,10,11])\n",
    "df_ventas_dic = filtrar_ventas_por_mes(df_ventas=df_ventas_agrupadas_by_prodConcat.copy(deep=True), lista_meses=[12])\n",
    "\n",
    "\n",
    "df_prediccion_v_real_dic_rl = prediccion_regresion_lineal(df_ventas_enero_nov=df_ventas_enero_nov.copy(deep=True), df_ventas_dic=df_ventas_dic.copy(deep=True))\n",
    "generar_excel_by_dataframe(df_prediccion_v_real_dic_rl, \"PREDICCION-DICIEMBRE-RL\")\n",
    "\n",
    "df_prediccion_v_real_dic_rf = prediccion_random_forest(df_ventas_enero_nov=df_ventas_enero_nov.copy(deep=True), df_ventas_dic=df_ventas_dic.copy(deep=True))\n",
    "generar_excel_by_dataframe(df_prediccion_v_real_dic_rf, \"PREDICCION-DICIEMBRE-RF\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
